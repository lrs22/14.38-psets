{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "stuck-borough",
   "metadata": {},
   "source": [
    "# Intro #\n",
    "First, I will load in the data from the the notebook on the gender wage gap, because that is what I will be using for this problem set. I will be considering two subsamples of the data. My \"young\" data will consist of workers with below median experience (experience less than or equal to 10 years) and my \"old\" data will consist of workers with above median experience (greater than 10 years). It will be interesting to see how the predictive power of our methods compare between groups.\n",
    "\n",
    "First, we will load in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "removable-yeast",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>5150</li>\n",
       "\t<li>20</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 5150\n",
       "\\item 20\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 5150\n",
       "2. 20\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 5150   20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t5150 obs. of  20 variables:\n",
      " $ wage : num  9.62 48.08 11.06 13.94 28.85 ...\n",
      " $ lwage: num  2.26 3.87 2.4 2.63 3.36 ...\n",
      " $ sex  : num  1 0 0 1 1 1 1 0 1 1 ...\n",
      " $ shs  : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ hsg  : num  0 0 1 0 0 0 1 1 1 0 ...\n",
      " $ scl  : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ clg  : num  1 1 0 0 1 1 0 0 0 1 ...\n",
      " $ ad   : num  0 0 0 1 0 0 0 0 0 0 ...\n",
      " $ mw   : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ so   : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ we   : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ ne   : num  1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ exp1 : num  7 31 18 25 22 1 42 37 31 4 ...\n",
      " $ exp2 : num  0.49 9.61 3.24 6.25 4.84 ...\n",
      " $ exp3 : num  0.343 29.791 5.832 15.625 10.648 ...\n",
      " $ exp4 : num  0.24 92.35 10.5 39.06 23.43 ...\n",
      " $ occ  : Factor w/ 369 levels \"10\",\"20\",\"40\",..: 159 136 269 23 99 86 226 232 184 146 ...\n",
      " $ occ2 : Factor w/ 22 levels \"1\",\"2\",\"3\",\"4\",..: 11 10 19 1 6 5 17 17 13 10 ...\n",
      " $ ind  : Factor w/ 236 levels \"370\",\"380\",\"390\",..: 204 117 12 165 231 176 171 135 210 201 ...\n",
      " $ ind2 : Factor w/ 21 levels \"2\",\"3\",\"4\",\"5\",..: 17 8 3 11 21 13 13 8 18 17 ...\n"
     ]
    }
   ],
   "source": [
    "library(tidyverse)\n",
    "\n",
    "load('ps1-wage-data')\n",
    "attach(data)\n",
    "dim(data)\n",
    "str(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-cooling",
   "metadata": {},
   "source": [
    "Now, we can filter the data and split it into our young and old groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "dying-thomas",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of obs in younger group: 2601 \n",
      "Number of obs in older group: 2549 \n"
     ]
    }
   ],
   "source": [
    "youngdata <- filter(data, exp1 <= 10)\n",
    "young.n <- dim(youngdata)[1]\n",
    "young.p <- dim(youngdata)[2]\n",
    "\n",
    "olddata <- filter(data, exp1 > 10)\n",
    "old.n <- dim(olddata)[1]\n",
    "old.p <- dim(youngdata)[2]\n",
    "\n",
    "cat(\"Number of obs in younger group:\", young.n, \"\\n\")\n",
    "cat(\"Number of obs in older group:\", old.n, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-remains",
   "metadata": {},
   "source": [
    "# Problem 1: Sample Splitting #\n",
    "\n",
    "Sample splitting is a procedure by which we evaluate the out of sample predictive performance of a given model. The basic procedure is this:\n",
    "1. Randomly split our data into \"training\" and \"testing\" groups.\n",
    "2. Use some method to estimate the parameters of our model using the training data.\n",
    "3. Use that model to predict our outcome variable for the data in the testing group.\n",
    "4. Evaluate the performance of the model using the difference between the prediction and the actual outcome variable in the testing group.\n",
    "\n",
    "Specifically, we will evaluate the performance of our model using out-of-sample $R^2$ and out-of-sample $MSE$.\n",
    "\n",
    "In general, we want our results to be robust to our choice of training data, so we create multiple different training groups, test the model based on them on our testing group, and average the goodness-of-fit statistics to determine the predictive ability of our model.\n",
    "\n",
    "We can also use multiple estimation strategies (like OLS, lasso, etc.) and compare those different methods of estimating the same model.\n",
    "\n",
    "For this sample splitting example, we will use one training and one testing group. However, we could also use multiple training groups and average their $R^2$ and $MSE$, which might yield some more robustness to our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-genetics",
   "metadata": {},
   "source": [
    "First, we randomly split up the data, because we only have 120 observations, I will have 3 groups of training data and 1 group of testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "attached-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seed for replicability\n",
    "set.seed(1)\n",
    "\n",
    "#splits into training and testing group\n",
    "young.random <- sample(1:young.n, size=floor(4/5*young.n))\n",
    "young.train <- youngdata[young.random,]\n",
    "young.test <- youngdata[-young.random,]\n",
    "\n",
    "old.random <- sample(1:old.n, size=floor(4/5*old.n))\n",
    "old.train <- olddata[old.random,]\n",
    "old.test <- olddata[-old.random,]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-david",
   "metadata": {},
   "source": [
    "Now we will estimate an additive model and a flexible model for our training group, test them using the testing group, and compare the $R^2_{test}$ and $MSE_{test}$ across the two subsets of data. We will also use lasso to estimate coefficients for the additive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "fifteen-globe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of additive regressors 24 \n",
      "Number of flexible regressors 226 \n"
     ]
    }
   ],
   "source": [
    "#additive model\n",
    "additive <- lwage ~ (sex + exp1 + occ2)\n",
    "young.addreg <- lm(additive, data=young.train)\n",
    "old.addreg <- lm(additive, data=old.train)\n",
    "\n",
    "p.add <- length(young.addreg$coef)\n",
    "\n",
    "#flexible\n",
    "flexible <- lwage ~ sex + (exp1+exp2+exp3+exp4)*(occ2+ind2+mw+so+we)\n",
    "young.flexreg <- lm(flexible, data=young.train)\n",
    "old.flexreg <- lm(flexible, data=old.train)\n",
    "\n",
    "p.flex <- length(young.flexreg$coef)\n",
    "\n",
    "library(hdm)\n",
    "\n",
    "#lasso regs\n",
    "young.lassoreg <- rlasso(additive, data=young.train)\n",
    "old.lassoreg <- rlasso(additive, data=old.train)\n",
    "\n",
    "cat(\"Number of additive regressors\", p.add, \"\\n\")\n",
    "cat(\"Number of flexible regressors\", p.flex, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-fusion",
   "metadata": {},
   "source": [
    "Now we can look at our out-of-sample performance measures for our 3 types of regressions: basic, flexible, and lasso.\n",
    "\n",
    "To do this, we will predict our outcome variable for our testing data using each of the previously generated models, and find their $R^2$ and $MSE$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "packed-tattoo",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in predict.lm(young.flexreg, newdata = young.test):\n",
      "“prediction from a rank-deficient fit may be misleading”Warning message in predict.lm(old.flexreg, newdata = old.test):\n",
      "“prediction from a rank-deficient fit may be misleading”"
     ]
    }
   ],
   "source": [
    "#save testing data wage for comparison\n",
    "young.actual <- young.test$lwage\n",
    "old.actual <- old.test$lwage\n",
    "\n",
    "#young additive\n",
    "young.trainadd <- predict(young.addreg, newdata=young.test)\n",
    "young.MSE.add <- sum((young.actual-young.trainadd)^2)/length(young.actual)\n",
    "young.R2.add <- 1 - young.MSE.add/var(young.actual)\n",
    "\n",
    "#young flex\n",
    "young.trainflex <- predict(young.flexreg, newdata=young.test)\n",
    "young.MSE.flex <- sum((young.actual-young.trainflex)^2)/length(young.actual)\n",
    "young.R2.flex <- 1 - young.MSE.flex/var(young.actual)\n",
    "\n",
    "#young lasso\n",
    "young.trainlasso <- predict(young.lassoreg, newdata=young.test)\n",
    "young.MSE.lasso <- sum((young.actual-young.trainlasso)^2)/length(young.actual)\n",
    "young.R2.lasso <- 1 - young.MSE.lasso/var(young.actual)\n",
    "\n",
    "#old additive\n",
    "old.trainadd <- predict(old.addreg, newdata=old.test)\n",
    "old.MSE.add <- sum((old.actual-old.trainadd)^2)/length(old.actual)\n",
    "old.R2.add <- 1 - old.MSE.add/var(old.actual)\n",
    "\n",
    "#old flex\n",
    "old.trainflex <- predict(old.flexreg, newdata=old.test)\n",
    "old.MSE.flex <- sum((old.actual-old.trainflex)^2)/length(old.actual)\n",
    "old.R2.flex <- 1 - old.MSE.flex/var(old.actual)\n",
    "\n",
    "#old lasso\n",
    "old.trainlasso <- predict(old.lassoreg, newdata=old.test)\n",
    "old.MSE.lasso <- sum((old.actual-old.trainlasso)^2)/length(old.actual)\n",
    "old.R2.lasso <- 1 - old.MSE.lasso/var(old.actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "democratic-texas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>$MSE_{test, y}$</th><th scope=col>$R^2_{test,y}$</th><th scope=col>$MSE_{test, o}$</th><th scope=col>$R^2_{test,o}$</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>basic reg</th><td>0.2290698 </td><td> 0.1712107</td><td>0.3134760 </td><td>0.15879090</td></tr>\n",
       "\t<tr><th scope=row>flexible reg</th><td>0.3423834 </td><td>-0.2387653</td><td>0.3365846 </td><td>0.09677906</td></tr>\n",
       "\t<tr><th scope=row>lasso reg</th><td>0.2348890 </td><td> 0.1501564</td><td>0.3199382 </td><td>0.14144949</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       "  & \\$MSE\\_\\{test, y\\}\\$ & \\$R\\textasciicircum{}2\\_\\{test,y\\}\\$ & \\$MSE\\_\\{test, o\\}\\$ & \\$R\\textasciicircum{}2\\_\\{test,o\\}\\$\\\\\n",
       "\\hline\n",
       "\tbasic reg & 0.2290698  &  0.1712107 & 0.3134760  & 0.15879090\\\\\n",
       "\tflexible reg & 0.3423834  & -0.2387653 & 0.3365846  & 0.09677906\\\\\n",
       "\tlasso reg & 0.2348890  &  0.1501564 & 0.3199382  & 0.14144949\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | $MSE_{test, y}$ | $R^2_{test,y}$ | $MSE_{test, o}$ | $R^2_{test,o}$ |\n",
       "|---|---|---|---|---|\n",
       "| basic reg | 0.2290698  |  0.1712107 | 0.3134760  | 0.15879090 |\n",
       "| flexible reg | 0.3423834  | -0.2387653 | 0.3365846  | 0.09677906 |\n",
       "| lasso reg | 0.2348890  |  0.1501564 | 0.3199382  | 0.14144949 |\n",
       "\n"
      ],
      "text/plain": [
       "             $MSE_{test, y}$ $R^2_{test,y}$ $MSE_{test, o}$ $R^2_{test,o}$\n",
       "basic reg    0.2290698        0.1712107     0.3134760       0.15879090    \n",
       "flexible reg 0.3423834       -0.2387653     0.3365846       0.09677906    \n",
       "lasso reg    0.2348890        0.1501564     0.3199382       0.14144949    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(xtable)\n",
    "\n",
    "table <- matrix(0, 3, 4)\n",
    "table[1,1]   <- young.MSE.add\n",
    "table[2,1]   <- young.MSE.flex\n",
    "table[3,1]   <- young.MSE.lasso\n",
    "table[1,2]   <- young.R2.add\n",
    "table[2,2]   <- young.R2.flex\n",
    "table[3,2]   <- young.R2.lasso\n",
    "table[1,3]   <- old.MSE.add\n",
    "table[2,3]   <- old.MSE.flex\n",
    "table[3,3]   <- old.MSE.lasso\n",
    "table[1,4]   <- old.R2.add\n",
    "table[2,4]   <- old.R2.flex\n",
    "table[3,4]   <- old.R2.lasso\n",
    "\n",
    "rownames(table)<- c(\"basic reg\",\"flexible reg\",\"lasso reg\")\n",
    "colnames(table)<- c(\"$MSE_{test, y}$\", \"$R^2_{test,y}$\", \"$MSE_{test, o}$\", \"$R^2_{test,o}$\")\n",
    "tab <- xtable(table, digits=c(3,3,3,3,3))\n",
    "tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-significance",
   "metadata": {},
   "source": [
    "As we can see, the flexible model does not perform well compared to the additive model, whether or not the additive model is estimated using OLS or lasso. In fact, the flexible regression does so poorly out of sample that its test $R^2$ is negative in the young group. The additive model performs better (but still not extremely way), with little difference between OLS and lasso estimation (OLS is slightly better). The additive model appears to perform slightly better in the younger group, whereas the flexible model performs better in the older group (but still poorly, overall)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-aluminum",
   "metadata": {},
   "source": [
    "# Problem 2: Gender Wage Gap #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-maker",
   "metadata": {},
   "source": [
    "In this section we will carry out an analysis of the gap in wage between men and women, among college educated workers. We will utilize the log-linear regression model \n",
    "\n",
    "$$\\log(Y) = \\beta_1D + \\beta_2'W + \\varepsilon$$ \n",
    "\n",
    "where $D$ is an indicator for being female and $W$ is a vector of controls. We can begin by estimating the simpler model \n",
    "\n",
    "$$\\log(Y) = \\beta D+\\varepsilon$$ \n",
    "\n",
    "This should provide us with the unconditional predictive effect of gender on wages, captured by $\\beta$.\n",
    "\n",
    "We use the same data as the previous problem, but we should first limit the sample to college educated workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "inside-mauritius",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t1636 obs. of  15 variables:\n",
      " $ wage : num  9.62 48.08 28.85 11.73 19.23 ...\n",
      " $ lwage: num  2.26 3.87 3.36 2.46 2.96 ...\n",
      " $ sex  : num  1 0 1 1 1 1 0 0 0 1 ...\n",
      " $ mw   : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ so   : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ we   : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ ne   : num  1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ exp1 : num  7 31 22 1 4 25 11 8 26 31 ...\n",
      " $ exp2 : num  0.49 9.61 4.84 0.01 0.16 6.25 1.21 0.64 6.76 9.61 ...\n",
      " $ exp3 : num  0.343 29.791 10.648 0.001 0.064 ...\n",
      " $ exp4 : num  0.2401 92.3521 23.4256 0.0001 0.0256 ...\n",
      " $ occ  : Factor w/ 369 levels \"10\",\"20\",\"40\",..: 159 136 99 86 146 7 264 241 267 120 ...\n",
      " $ occ2 : Factor w/ 22 levels \"1\",\"2\",\"3\",\"4\",..: 11 10 6 5 10 1 19 17 19 9 ...\n",
      " $ ind  : Factor w/ 236 levels \"370\",\"380\",\"390\",..: 204 117 231 176 201 190 12 111 152 111 ...\n",
      " $ ind2 : Factor w/ 21 levels \"2\",\"3\",\"4\",\"5\",..: 17 8 21 13 17 16 3 8 10 8 ...\n"
     ]
    }
   ],
   "source": [
    "coldata <- filter(data, clg == 1)\n",
    "coldata <- select(coldata, -c(shs, hsg, scl, clg, ad))\n",
    "str(coldata) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "democratic-burner",
   "metadata": {},
   "source": [
    "We can now run the simple (unconditional) regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "healthy-municipality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: -0.06236138 \n",
      "Robust SE: 0.02578365"
     ]
    }
   ],
   "source": [
    "library(sandwich) #used for robust SEs\n",
    "\n",
    "nocontrol.fit <- lm(lwage ~ sex, data=coldata)\n",
    "nocontrol.est <- summary(nocontrol.fit)$coef[\"sex\",1]\n",
    "\n",
    "#robust SEs using vcovHC from sandwich\n",
    "HCV.coefs <- vcovHC(nocontrol.fit, type='HC')\n",
    "nocontrol.se <- sqrt(diag(HCV.coefs))[2]\n",
    "\n",
    "cat(\"Coefficient:\", nocontrol.est, \"\\n\")\n",
    "cat(\"Robust SE:\", nocontrol.se)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-johnston",
   "metadata": {},
   "source": [
    "Now we will add controls, which will be the same as the flexible model from earlier (besides education, because of our limited sample)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "rational-confusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient with controls: -0.0462223 \n",
      "Robust SE: 0.02389685"
     ]
    }
   ],
   "source": [
    "flex.model <- lwage ~ sex + (exp1+exp2+exp3+exp4)*(occ2+ind2+mw+so+we)\n",
    "\n",
    "control.fit <- lm(flex.model, data=coldata)\n",
    "control.est <- control.fit$coef[2]\n",
    "\n",
    "HCV.coefs <- vcovHC(control.fit, type = 'HC')\n",
    "control.se <- sqrt(diag(HCV.coefs))[2]\n",
    "\n",
    "cat(\"Coefficient with controls:\", control.est, \"\\n\")\n",
    "cat(\"Robust SE:\", control.se)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-welding",
   "metadata": {},
   "source": [
    "Notice that while in the original notebook, the controls increased the magnitude of the predictive effect, they decreased the magnitude of the predictive effect in the college educated sample. Now that we have our controlled (conditioned) predictive effect, we can demonstrate the partialling out technique. To do so, we regress our outcome variable and regressor of interest on controls separately. We can then take the residuals and use them in a new model. Put formally, we estimate \n",
    "\n",
    "$$\\log(Y) = \\beta_1' W + \\varepsilon \\\\ D = \\beta_2' W + \\tilde{d}$$\n",
    "\n",
    "and store the residuals. We then estimate\n",
    "\n",
    "$$\\varepsilon = \\beta \\tilde{d} + \\xi$$\n",
    "\n",
    "from the residuals. As it turns out, $\\beta$ here is exactly equal to $\\beta_1$ from the flexible model above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "english-malaysia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient from partialling out: -0.0462223 \n",
      "Robust SE: 0.02389685 \n",
      "Confidence interval:"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>2.5 %</dt>\n",
       "\t\t<dd>-0.0929335873576592</dd>\n",
       "\t<dt>97.5 %</dt>\n",
       "\t\t<dd>0.000488986404549023</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[2.5 \\textbackslash{}\\%] -0.0929335873576592\n",
       "\\item[97.5 \\textbackslash{}\\%] 0.000488986404549023\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "2.5 %\n",
       ":   -0.092933587357659297.5 %\n",
       ":   0.000488986404549023\n",
       "\n"
      ],
      "text/plain": [
       "        2.5 %        97.5 % \n",
       "-0.0929335874  0.0004889864 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#models from which we get resids\n",
    "flex.y <- lwage ~ (exp1+exp2+exp3+exp4)*(occ2+ind2+mw+so+we)\n",
    "flex.d <- sex ~ (exp1+exp2+exp3+exp4)*(occ2+ind2+mw+so+we)\n",
    "\n",
    "#resid storage\n",
    "resid.Y <- lm(flex.y, data=coldata)$res\n",
    "resid.D <- lm(flex.d, data=coldata)$res\n",
    "\n",
    "#fitting from resids\n",
    "partial.fit <- lm(resid.Y ~ resid.D)\n",
    "partial.est <- partial.fit$coef[2]\n",
    "\n",
    "#robust SEs\n",
    "HCV.coefs <- vcovHC(partial.fit, type = 'HC')\n",
    "partial.se <- sqrt(diag(HCV.coefs))[2]\n",
    "\n",
    "cat(\"Coefficient from partialling out:\", partial.est, \"\\n\")\n",
    "cat(\"Robust SE:\", partial.se, \"\\n\")\n",
    "\n",
    "#confidence interval\n",
    "cat(\"Confidence interval:\")\n",
    "confint(partial.fit)[2,]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confidential-official",
   "metadata": {},
   "source": [
    "Note that both the coefficient and the standard error is exactly the same from the flexible model above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-radiation",
   "metadata": {},
   "source": [
    "Partialling out using OLS works very well when the number of regressors, $p$, is low relative to the sample size $n$. Are we in that setting, though? We can check our data dimensions using the flexible model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "specific-gospel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of regressors: 226 \n",
      "Number of observations 1636 \n"
     ]
    }
   ],
   "source": [
    "n <- dim(coldata)[1]\n",
    "p <- length(control.fit$coef)\n",
    "\n",
    "cat(\"Number of regressors:\", p, \"\\n\")\n",
    "cat(\"Number of observations\", n, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-incentive",
   "metadata": {},
   "source": [
    "Perhaps we aren't super concerned with OLS performance in this setting, but $p/n$ is certainly not small here. Therefore, we can use partialling out with lasso regression to improve performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "certified-cable",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient from lasso partialling: -0.02070625 \n",
      "Robust SE: 0.02470303"
     ]
    }
   ],
   "source": [
    "#partialling out the effect of W with Lasso\n",
    "resid.Y <- rlasso(flex.y, data=coldata)$res\n",
    "resid.D <- rlasso(flex.d, data=coldata)$res\n",
    "\n",
    "#fitting from resids\n",
    "partial.lasso.fit <- lm(resid.Y ~ resid.D)\n",
    "partial.lasso.est <- partial.lasso.fit$coef[2]\n",
    "\n",
    "#standard error\n",
    "HCV.coefs <- vcovHC(partial.lasso.fit, type = 'HC')\n",
    "partial.lasso.se <- sqrt(diag(HCV.coefs))[2]\n",
    "\n",
    "cat(\"Coefficient from lasso partialling:\", partial.lasso.est, \"\\n\")\n",
    "cat(\"Robust SE:\", partial.lasso.se)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smaller-hughes",
   "metadata": {},
   "source": [
    "The results here are actually fairly different from those of OLS. The magnitude has decreased by about half, and is not even marginally significant. We can summarize our results in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "valid-giving",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Estimate</th><th scope=col>Std. Error</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Without controls</th><td>-0.06236138</td><td>0.02578365 </td></tr>\n",
       "\t<tr><th scope=row>full reg</th><td>-0.04622230</td><td>0.02389685 </td></tr>\n",
       "\t<tr><th scope=row>partial reg</th><td>-0.04622230</td><td>0.02389685 </td></tr>\n",
       "\t<tr><th scope=row>partial reg via lasso</th><td>-0.02070625</td><td>0.02470303 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & Estimate & Std. Error\\\\\n",
       "\\hline\n",
       "\tWithout controls & -0.06236138 & 0.02578365 \\\\\n",
       "\tfull reg & -0.04622230 & 0.02389685 \\\\\n",
       "\tpartial reg & -0.04622230 & 0.02389685 \\\\\n",
       "\tpartial reg via lasso & -0.02070625 & 0.02470303 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Estimate | Std. Error |\n",
       "|---|---|---|\n",
       "| Without controls | -0.06236138 | 0.02578365  |\n",
       "| full reg | -0.04622230 | 0.02389685  |\n",
       "| partial reg | -0.04622230 | 0.02389685  |\n",
       "| partial reg via lasso | -0.02070625 | 0.02470303  |\n",
       "\n"
      ],
      "text/plain": [
       "                      Estimate    Std. Error\n",
       "Without controls      -0.06236138 0.02578365\n",
       "full reg              -0.04622230 0.02389685\n",
       "partial reg           -0.04622230 0.02389685\n",
       "partial reg via lasso -0.02070625 0.02470303"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table<- matrix(0,4,2)\n",
    "table[1,1]<- nocontrol.est  \n",
    "table[1,2]<- nocontrol.se   \n",
    "table[2,1]<- control.est\n",
    "table[2,2]<- control.se    \n",
    "table[3,1]<- partial.est  \n",
    "table[3,2]<- partial.se  \n",
    "table[4,1]<-  partial.lasso.est\n",
    "table[4,2]<- partial.lasso.se\n",
    "colnames(table)<- c(\"Estimate\",\"Std. Error\")\n",
    "rownames(table)<- c(\"Without controls\", \"full reg\", \"partial reg\", \"partial reg via lasso\")\t\n",
    "tab<- xtable(table, digits=c(3, 3, 4))\n",
    "tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-corporation",
   "metadata": {},
   "source": [
    "Note that although standard errors stay consistent throughout the different models, the magnitude steadily decreases. When doing partial reg via lasso, we see a result that is not statistically significant. This differs from what we see in the unrestricted sample, where adding controls icnreased the estimated predictive effect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-honolulu",
   "metadata": {},
   "source": [
    "We can now try a VERY flexible model, by including all interaction terms possible given our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "federal-spread",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of regressors: 778 \n"
     ]
    }
   ],
   "source": [
    "extraflex <- lwage ~ sex + (exp1+exp2+exp3+exp4+occ2+ind2+mw+so+we)^2\n",
    "control.fit <- lm(extraflex, data=data)\n",
    "\n",
    "p <- length(control.fit$coef)\n",
    "cat(\"Number of regressors:\", p, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-tension",
   "metadata": {},
   "source": [
    "As we can see, $p/n$ has now exceeded 0.5, so this is falling into a high dimensional case. Therefore, partialling out via lasso is the way we should handle this data. We can compare its estimates to others as well. First, we estimate with standard OLS as a point of comparison, then we use lasso to partial out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "entertaining-underwear",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient for OLS with extra flex controls -0.07069553 \n",
      "Robust SE: 0.02207069 \n"
     ]
    }
   ],
   "source": [
    "control.est <- control.fit$coef[2]\n",
    "\n",
    "cat(\"Coefficient for OLS with extra flex controls\", control.est, \"\\n\")\n",
    "\n",
    "\n",
    "HCV.coefs <- vcovHC(control.fit, type = 'HC');\n",
    "\n",
    "n= dim(coldata)[1]; p =length(control.fit$coef);\n",
    "\n",
    "#must adjust standard errors for high dimensional case\n",
    "control.se <- sqrt(diag(HCV.coefs))[2]*sqrt(n/(n-p)) \n",
    "\n",
    "cat(\"Robust SE:\", control.se, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "refined-chase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient from lasso partialling: -0.01826163 \n",
      "Robust SE: 0.02487689"
     ]
    }
   ],
   "source": [
    "# models\n",
    "extraflex.y <- lwage ~ (exp1+exp2+exp3+exp4+occ2+ind2+mw+so+we)^2\n",
    "extraflex.d <- sex ~ (exp1+exp2+exp3+exp4+occ2+ind2+mw+so+we)^2\n",
    "\n",
    "#partialling out the effect of W with Lasso\n",
    "resid.Y <- rlasso(extraflex.y, data=coldata)$res\n",
    "resid.D <- rlasso(extraflex.d, data=coldata)$res\n",
    "\n",
    "#fitting from resids\n",
    "partial.lasso.fit <- lm(resid.Y ~ resid.D)\n",
    "partial.lasso.est <- partial.lasso.fit$coef[2]\n",
    "\n",
    "#standard error\n",
    "HCV.coefs <- vcovHC(partial.lasso.fit, type = 'HC')\n",
    "partial.lasso.se <- sqrt(diag(HCV.coefs))[2]\n",
    "\n",
    "cat(\"Coefficient from lasso partialling:\", partial.lasso.est, \"\\n\")\n",
    "cat(\"Robust SE:\", partial.lasso.se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "monthly-patient",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Estimate</th><th scope=col>Std. Error</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>full reg</th><td>-0.07069553</td><td>0.02207069 </td></tr>\n",
       "\t<tr><th scope=row>partial reg via lasso</th><td>-0.01826163</td><td>0.02487689 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & Estimate & Std. Error\\\\\n",
       "\\hline\n",
       "\tfull reg & -0.07069553 & 0.02207069 \\\\\n",
       "\tpartial reg via lasso & -0.01826163 & 0.02487689 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Estimate | Std. Error |\n",
       "|---|---|---|\n",
       "| full reg | -0.07069553 | 0.02207069  |\n",
       "| partial reg via lasso | -0.01826163 | 0.02487689  |\n",
       "\n"
      ],
      "text/plain": [
       "                      Estimate    Std. Error\n",
       "full reg              -0.07069553 0.02207069\n",
       "partial reg via lasso -0.01826163 0.02487689"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table<- matrix(0, 2, 2)\n",
    "table[1,1]<- control.est\n",
    "table[1,2]<- control.se    \n",
    "table[2,1]<-  partial.lasso.est\n",
    "table[2,2]<- partial.lasso.se \n",
    "colnames(table)<- c(\"Estimate\",\"Std. Error\")\n",
    "rownames(table)<- c(\"full reg\",\"partial reg via lasso\")\t\n",
    "tab<- xtable(table, digits=c(3, 3, 4))\n",
    "tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-disclaimer",
   "metadata": {},
   "source": [
    "As we can see, the results from our partial regression via lasso differ significantly from the OLS results. The magnitude is very small, and statistically insigificant. In this setting, with $p >> n$, we might trust the results from partialling via lasso more than OLS, because OLS inference does not work properly in the high dimensional case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
